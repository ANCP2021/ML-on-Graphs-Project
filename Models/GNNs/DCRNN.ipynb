{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import MSELoss\n",
    "from torch_geometric.utils import to_dense_adj, dense_to_sparse\n",
    "from torch_geometric.nn.conv import MessagePassing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    DATE   HARE   LYNX\n",
      "0   1845  19.58  30.09\n",
      "1   1846  19.60  45.15\n",
      "2   1847  19.61  49.15\n",
      "3   1848  11.99  39.52\n",
      "4   1849  28.04  21.23\n",
      "..   ...    ...    ...\n",
      "86  1931  19.52   8.31\n",
      "87  1932  82.11  16.01\n",
      "88  1933  89.76  24.82\n",
      "89  1934  81.66  29.70\n",
      "90  1935  15.76  35.40\n",
      "\n",
      "[91 rows x 3 columns]\n",
      "    DATE   HARE   LYNX  HARE_lag1  LYNX_lag1\n",
      "1   1846  19.60  45.15      19.58      30.09\n",
      "2   1847  19.61  49.15      19.60      45.15\n",
      "3   1848  11.99  39.52      19.61      49.15\n",
      "4   1849  28.04  21.23      11.99      39.52\n",
      "5   1850  58.00   8.42      28.04      21.23\n",
      "..   ...    ...    ...        ...        ...\n",
      "86  1931  19.52   8.31       4.23       6.98\n",
      "87  1932  82.11  16.01      19.52       8.31\n",
      "88  1933  89.76  24.82      82.11      16.01\n",
      "89  1934  81.66  29.70      89.76      24.82\n",
      "90  1935  15.76  35.40      81.66      29.70\n",
      "\n",
      "[90 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../../Datasets/Lynx_Hare/data.csv', usecols=['DATE', 'HARE', 'LYNX'])\n",
    "print(df)\n",
    "\n",
    "# Create lagged features for one-step ahead prediction\n",
    "df['HARE_lag1'] = df['HARE'].shift(1)\n",
    "df['LYNX_lag1'] = df['LYNX'].shift(1)\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Define features (x) and targets (y)\n",
    "x = df[['HARE_lag1', 'LYNX_lag1']].values  # previous time step's data as input\n",
    "y = df[['HARE', 'LYNX']].values  \n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential split for training and testing\n",
    "split_idx = int(len(x) * 0.8)\n",
    "x_train, x_test = x[:split_idx], x[split_idx:]\n",
    "y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "x_train = torch.tensor(x_train, dtype=torch.float)\n",
    "x_test = torch.tensor(x_test, dtype=torch.float)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = torch.tensor([[0], [1]], dtype=torch.long)  # Lynx -> Hare\n",
    "\n",
    "data_train = Data(x=x_train, edge_index=edge_index)\n",
    "data_test = Data(x=x_test, edge_index=edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DConv(MessagePassing):\n",
    "    \"\"\"An implementation of the Diffusion Convolution Layer.\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, K, bias=True):\n",
    "        super(DConv, self).__init__(aggr=\"add\", flow=\"source_to_target\")\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.K = K\n",
    "        self.weight = torch.nn.Parameter(torch.Tensor(2, K, in_channels, out_channels))\n",
    "        if bias:\n",
    "            self.bias = torch.nn.Parameter(torch.Tensor(out_channels))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        torch.nn.init.xavier_uniform_(self.weight)\n",
    "        if self.bias is not None:\n",
    "            torch.nn.init.zeros_(self.bias)\n",
    "\n",
    "    def forward(self, X, edge_index, edge_weight):\n",
    "        adj_mat = to_dense_adj(edge_index, edge_attr=edge_weight)\n",
    "        adj_mat = adj_mat.squeeze(0)  # Remove batch dim\n",
    "        Tx_0 = X\n",
    "        H = torch.matmul(Tx_0, self.weight[0][0])\n",
    "        if self.K > 1:\n",
    "            norm = torch.matmul(adj_mat, torch.ones(X.size(0), 1, device=X.device)).squeeze()\n",
    "            Tx_1 = self.propagate(edge_index, x=Tx_0, norm=norm)\n",
    "            H += torch.matmul(Tx_1, self.weight[0][1])\n",
    "        for k in range(2, self.K):\n",
    "            Tx_2 = self.propagate(edge_index, x=Tx_1, norm=norm)\n",
    "            H += torch.matmul(Tx_2, self.weight[0][k])\n",
    "            Tx_1 = Tx_2\n",
    "        if self.bias is not None:\n",
    "            H += self.bias\n",
    "        return H\n",
    "\n",
    "class DCRNN(torch.nn.Module):\n",
    "    \"\"\"An implementation of the Diffusion Convolutional Gated Recurrent Unit.\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, K, bias=True):\n",
    "        super(DCRNN, self).__init__()\n",
    "        self.dconv = DConv(in_channels, out_channels, K, bias)\n",
    "\n",
    "    def forward(self, X, edge_index, edge_weight=None, H=None):\n",
    "        if H is None:\n",
    "            H = torch.zeros_like(X)\n",
    "        Z = self.dconv(X, edge_index, edge_weight)\n",
    "        R = self.dconv(X, edge_index, edge_weight)\n",
    "        H_tilde = self.dconv(X * R, edge_index, edge_weight)\n",
    "        H_new = Z * H + (1 - Z) * H_tilde\n",
    "        return H_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DCRNN(in_channels=2, out_channels=2, K=2)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "DCRNN.forward() missing 1 required positional argument: 'edge_index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m      6\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m----> 7\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m criterion(out, y_train)\n\u001b[1;32m      9\u001b[0m train_loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: DCRNN.forward() missing 1 required positional argument: 'edge_index'"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "for epoch in range(200):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data_train)\n",
    "    train_loss = criterion(out, y_train)\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    model.eval()  \n",
    "    with torch.no_grad(): # gradient is not computed\n",
    "        test_pred = model(data_test)\n",
    "        test_loss = criterion(test_pred, y_test)\n",
    "    \n",
    "    train_losses.append(train_loss.item())\n",
    "    test_losses.append(test_loss.item())\n",
    "\n",
    "# training and testing losses\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(test_losses, label='Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Test Loss Over Epochs')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "model.eval() \n",
    "with torch.no_grad(): \n",
    "    final_pred = model(data_test)\n",
    "    final_mse_test = criterion(final_pred, y_test)\n",
    "\n",
    "print(f'Final Test MSE: {final_mse_test.item()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
